{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-08T14:17:00.948423Z",
     "start_time": "2026-02-08T14:16:56.481932Z"
    }
   },
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from nodes.question_nodes import plan, summarise, should_break_query, human_feedback, is_finished, should_skip_human_feedback\n",
    "from nodes.search_nodes import search_web\n",
    "from nodes.review_nodes import review\n",
    "\n",
    "from state import WebSearchState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Add nodes and edges\n",
    "builder = StateGraph(state_schema=WebSearchState)\n",
    "builder.add_node(\"plan\", plan)\n",
    "builder.add_node(\"search_web\", search_web)\n",
    "builder.add_node(\"summarise\", summarise)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"review\", review)\n",
    "\n",
    "builder.add_edge(START, \"plan\")\n",
    "builder.add_conditional_edges(\"plan\", should_skip_human_feedback, [\"human_feedback\", \"search_web\"])\n",
    "builder.add_conditional_edges(\"human_feedback\", should_break_query, [\"plan\", \"search_web\"])\n",
    "\n",
    "builder.add_edge(\"search_web\", \"summarise\")\n",
    "builder.add_edge(\"summarise\", \"review\")\n",
    "builder.add_conditional_edges(\"review\", is_finished, [END, \"plan\", \"summarise\"])\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory, interrupt_before=[\"human_feedback\"])\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T14:18:42.502084Z",
     "start_time": "2026-02-08T14:17:00.954936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Initial invoke - generates sub-questions and stops\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in graph.stream(\n",
    "    {\"query\": \"What's the difference between LangSmith and LangGraph?\"},\n",
    "    thread, stream_mode=\"updates\"\n",
    "):\n",
    "    print(event)\n",
    "\n",
    "# Step 2: Check generated questions\n",
    "state = graph.get_state(thread)\n",
    "print(\"Generated questions:\", state.values.get(\"questions\"))\n",
    "\n",
    "# Get user input\n",
    "user_input = input(\"Tell me how you want to update the questions: \")\n",
    "\n",
    "# We now update the state as if we are the human_feedback node\n",
    "graph.update_state(thread, {\"human_feedback\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "\n",
    "# Step 4: Check final results\n",
    "final_state = graph.get_state(thread)\n",
    "print(\"Summary:\", final_state.values.get(\"summary\"))\n"
   ],
   "id": "ddd0b20722201908",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sub-questions\n",
      "{'plan': {'query': \"What's the difference between LangSmith and LangGraph?\", 'break_questions_iterations_count': 1, 'questions': ['What are the key features and functionalities of LangSmith?', 'What are the key features and functionalities of LangGraph?'], 'messages': [AIMessage(content=\"I'm now going to search for these topics:**1**. **What are the key features and functionalities of LangSmith?**\\n**2**. **What are the key features and functionalities of LangGraph?**\", additional_kwargs={}, response_metadata={}, id='1c071af1-e632-4054-8159-6e68bbf5d46a', tool_calls=[], invalid_tool_calls=[])]}}\n",
      "{'__interrupt__': ()}\n",
      "Generated questions: ['What are the key features and functionalities of LangSmith?', 'What are the key features and functionalities of LangGraph?']\n",
      "Considering human feedback ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m user_input = \u001B[38;5;28minput\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTell me how you want to update the questions: \u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# We now update the state as if we are the human_feedback node\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[43mgraph\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupdate_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhuman_feedback\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_input\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_node\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhuman_feedback\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# Continue the graph execution\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m graph.stream(\u001B[38;5;28;01mNone\u001B[39;00m, thread, stream_mode=\u001B[33m\"\u001B[39m\u001B[33mupdates\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2320\u001B[39m, in \u001B[36mPregel.update_state\u001B[39m\u001B[34m(self, config, values, as_node, task_id)\u001B[39m\n\u001B[32m   2309\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mupdate_state\u001B[39m(\n\u001B[32m   2310\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   2311\u001B[39m     config: RunnableConfig,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2314\u001B[39m     task_id: \u001B[38;5;28mstr\u001B[39m | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   2315\u001B[39m ) -> RunnableConfig:\n\u001B[32m   2316\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Update the state of the graph with the given values, as if they came from\u001B[39;00m\n\u001B[32m   2317\u001B[39m \u001B[33;03m    node `as_node`. If `as_node` is not provided, it will be set to the last node\u001B[39;00m\n\u001B[32m   2318\u001B[39m \u001B[33;03m    that updated the state, if not ambiguous.\u001B[39;00m\n\u001B[32m   2319\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2320\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbulk_update_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mStateUpdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_node\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask_id\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:1866\u001B[39m, in \u001B[36mPregel.bulk_update_state\u001B[39m\u001B[34m(self, config, supersteps)\u001B[39m\n\u001B[32m   1862\u001B[39m current_config = patch_configurable(\n\u001B[32m   1863\u001B[39m     config, {CONFIG_KEY_THREAD_ID: \u001B[38;5;28mstr\u001B[39m(config[CONF][CONFIG_KEY_THREAD_ID])}\n\u001B[32m   1864\u001B[39m )\n\u001B[32m   1865\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m superstep \u001B[38;5;129;01min\u001B[39;00m supersteps:\n\u001B[32m-> \u001B[39m\u001B[32m1866\u001B[39m     current_config = \u001B[43mperform_superstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuperstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1867\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m current_config\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:1801\u001B[39m, in \u001B[36mPregel.bulk_update_state.<locals>.perform_superstep\u001B[39m\u001B[34m(input_config, updates)\u001B[39m\n\u001B[32m   1799\u001B[39m     run = RunnableSequence(*writers) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(writers) > \u001B[32m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m writers[\u001B[32m0\u001B[39m]\n\u001B[32m   1800\u001B[39m     \u001B[38;5;66;03m# execute task\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1801\u001B[39m     \u001B[43mrun\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1802\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1803\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpatch_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1804\u001B[39m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1805\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mUpdateState\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1806\u001B[39m \u001B[43m            \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m   1807\u001B[39m \u001B[43m                \u001B[49m\u001B[38;5;66;43;03m# deque.extend is thread-safe\u001B[39;49;00m\n\u001B[32m   1808\u001B[39m \u001B[43m                \u001B[49m\u001B[43mCONFIG_KEY_SEND\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mwrites\u001B[49m\u001B[43m.\u001B[49m\u001B[43mextend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1809\u001B[39m \u001B[43m                \u001B[49m\u001B[43mCONFIG_KEY_TASK_ID\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1810\u001B[39m \u001B[43m                \u001B[49m\u001B[43mCONFIG_KEY_READ\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1811\u001B[39m \u001B[43m                    \u001B[49m\u001B[43mlocal_read\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1812\u001B[39m \u001B[43m                    \u001B[49m\u001B[43m_scratchpad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1813\u001B[39m \u001B[43m                        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1814\u001B[39m \u001B[43m                        \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1815\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mtask_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1816\u001B[39m \u001B[43m                        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1817\u001B[39m \u001B[43m                        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1818\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1819\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1820\u001B[39m \u001B[43m                    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1821\u001B[39m \u001B[43m                    \u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1822\u001B[39m \u001B[43m                    \u001B[49m\u001B[43mmanaged\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1823\u001B[39m \u001B[43m                    \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1824\u001B[39m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1825\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1826\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1827\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1828\u001B[39m \u001B[38;5;66;03m# save task writes\u001B[39;00m\n\u001B[32m   1829\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m task_id, task \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(run_task_ids, run_tasks):\n\u001B[32m   1830\u001B[39m     \u001B[38;5;66;03m# channel writes are saved to current checkpoint\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3153\u001B[39m, in \u001B[36mRunnableSequence.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3151\u001B[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001B[32m   3152\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3153\u001B[39m                 input_ = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3154\u001B[39m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[32m   3155\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001B[39m, in \u001B[36mRunnableCallable.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    398\u001B[39m         run_manager.on_chain_end(ret)\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m400\u001B[39m     ret = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    401\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.recurse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable):\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ret.invoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langgraph\\graph\\_branch.py:166\u001B[39m, in \u001B[36mBranchSpec._route\u001B[39m\u001B[34m(self, input, config, reader, writer)\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    165\u001B[39m     value = \u001B[38;5;28minput\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    167\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._finish(writer, \u001B[38;5;28minput\u001B[39m, result, config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:393\u001B[39m, in \u001B[36mRunnableCallable.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    391\u001B[39m     \u001B[38;5;66;03m# run in context\u001B[39;00m\n\u001B[32m    392\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(child_config, run) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[32m--> \u001B[39m\u001B[32m393\u001B[39m         ret = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    395\u001B[39m     run_manager.on_chain_error(e)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\src\\nodes\\question_nodes.py:188\u001B[39m, in \u001B[36mshould_break_query\u001B[39m\u001B[34m(state)\u001B[39m\n\u001B[32m    175\u001B[39m     messages.append(HumanMessage(content=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mHuman Feedback: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhuman_feedback\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m))\n\u001B[32m    177\u001B[39m messages.append(\n\u001B[32m    178\u001B[39m     SystemMessage(\n\u001B[32m    179\u001B[39m         content=\u001B[33m\"\u001B[39m\u001B[33mBased on the above information, decide the next step. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    185\u001B[39m     )\n\u001B[32m    186\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m188\u001B[39m result = \u001B[43mstructured_router\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    189\u001B[39m next_step = result.next_step\n\u001B[32m    190\u001B[39m next_step_reason = result.reason\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3151\u001B[39m, in \u001B[36mRunnableSequence.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3149\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(config) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[32m   3150\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i == \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m3151\u001B[39m         input_ = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3152\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   3153\u001B[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5691\u001B[39m, in \u001B[36mRunnableBindingBase.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5684\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5685\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m   5686\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5689\u001B[39m     **kwargs: Any | \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   5690\u001B[39m ) -> Output:\n\u001B[32m-> \u001B[39m\u001B[32m5691\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbound\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   5692\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   5693\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5694\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5695\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    388\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    389\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    390\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    395\u001B[39m     **kwargs: Any,\n\u001B[32m    396\u001B[39m ) -> AIMessage:\n\u001B[32m    397\u001B[39m     config = ensure_config(config)\n\u001B[32m    398\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    399\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAIMessage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    400\u001B[39m         cast(\n\u001B[32m    401\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m402\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m                \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    405\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[43m                \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[43m                \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    408\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    409\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    410\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    411\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    412\u001B[39m         ).message,\n\u001B[32m    413\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1112\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   1113\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m   1114\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1118\u001B[39m     **kwargs: Any,\n\u001B[32m   1119\u001B[39m ) -> LLMResult:\n\u001B[32m   1120\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1121\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    928\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    929\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    930\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m931\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    932\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    933\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    934\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    935\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    936\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    937\u001B[39m         )\n\u001B[32m    938\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    939\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1231\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1232\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1233\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1234\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1235\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1236\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1237\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1030\u001B[39m, in \u001B[36mChatOllama._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1023\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_generate\u001B[39m(\n\u001B[32m   1024\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1025\u001B[39m     messages: \u001B[38;5;28mlist\u001B[39m[BaseMessage],\n\u001B[32m   (...)\u001B[39m\u001B[32m   1028\u001B[39m     **kwargs: Any,\n\u001B[32m   1029\u001B[39m ) -> ChatResult:\n\u001B[32m-> \u001B[39m\u001B[32m1030\u001B[39m     final_chunk = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_chat_stream_with_aggregation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1031\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1032\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1033\u001B[39m     generation_info = final_chunk.generation_info\n\u001B[32m   1034\u001B[39m     chat_generation = ChatGeneration(\n\u001B[32m   1035\u001B[39m         message=AIMessage(\n\u001B[32m   1036\u001B[39m             content=final_chunk.text,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1043\u001B[39m         generation_info=generation_info,\n\u001B[32m   1044\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:965\u001B[39m, in \u001B[36mChatOllama._chat_stream_with_aggregation\u001B[39m\u001B[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001B[39m\n\u001B[32m    956\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_chat_stream_with_aggregation\u001B[39m(\n\u001B[32m    957\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    958\u001B[39m     messages: \u001B[38;5;28mlist\u001B[39m[BaseMessage],\n\u001B[32m   (...)\u001B[39m\u001B[32m    962\u001B[39m     **kwargs: Any,\n\u001B[32m    963\u001B[39m ) -> ChatGenerationChunk:\n\u001B[32m    964\u001B[39m     final_chunk = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m965\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iterate_over_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    966\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfinal_chunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[32m    967\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfinal_chunk\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1054\u001B[39m, in \u001B[36mChatOllama._iterate_over_stream\u001B[39m\u001B[34m(self, messages, stop, **kwargs)\u001B[39m\n\u001B[32m   1047\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_iterate_over_stream\u001B[39m(\n\u001B[32m   1048\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1049\u001B[39m     messages: \u001B[38;5;28mlist\u001B[39m[BaseMessage],\n\u001B[32m   1050\u001B[39m     stop: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1051\u001B[39m     **kwargs: Any,\n\u001B[32m   1052\u001B[39m ) -> Iterator[ChatGenerationChunk]:\n\u001B[32m   1053\u001B[39m     reasoning = kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mreasoning\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m.reasoning)\n\u001B[32m-> \u001B[39m\u001B[32m1054\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create_chat_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1055\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1056\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1057\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessage\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcontent\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m   1058\u001B[39m \u001B[43m                \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessage\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcontent\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessage\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m   1059\u001B[39m \u001B[43m                \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m   1060\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:952\u001B[39m, in \u001B[36mChatOllama._create_chat_stream\u001B[39m\u001B[34m(self, messages, stop, **kwargs)\u001B[39m\n\u001B[32m    950\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chat_params[\u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m    951\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client:\n\u001B[32m--> \u001B[39m\u001B[32m952\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.chat(**chat_params)\n\u001B[32m    953\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client:\n\u001B[32m    954\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.chat(**chat_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\ollama\\_client.py:181\u001B[39m, in \u001B[36mClient._request.<locals>.inner\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    178\u001B[39m   e.response.read()\n\u001B[32m    179\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m ResponseError(e.response.text, e.response.status_code) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m181\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m.\u001B[49m\u001B[43miter_lines\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[43m  \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[43m  \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43merr\u001B[49m\u001B[43m \u001B[49m\u001B[43m:=\u001B[49m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43merror\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpx\\_models.py:929\u001B[39m, in \u001B[36mResponse.iter_lines\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    927\u001B[39m decoder = LineDecoder()\n\u001B[32m    928\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m929\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpx\\_models.py:916\u001B[39m, in \u001B[36mResponse.iter_text\u001B[39m\u001B[34m(self, chunk_size)\u001B[39m\n\u001B[32m    914\u001B[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001B[32m    915\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m916\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbyte_content\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtext_content\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbyte_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_content\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpx\\_models.py:897\u001B[39m, in \u001B[36mResponse.iter_bytes\u001B[39m\u001B[34m(self, chunk_size)\u001B[39m\n\u001B[32m    895\u001B[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001B[32m    896\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m897\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mraw_bytes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    898\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdecoded\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_bytes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    899\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdecoded\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpx\\_models.py:951\u001B[39m, in \u001B[36mResponse.iter_raw\u001B[39m\u001B[34m(self, chunk_size)\u001B[39m\n\u001B[32m    948\u001B[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001B[32m    950\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m951\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    952\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_num_bytes_downloaded\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    953\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpx\\_client.py:153\u001B[39m, in \u001B[36mBoundSyncStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> typing.Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    154\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001B[39m, in \u001B[36mResponseStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> typing.Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[32m    126\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_httpcore_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001B[39m, in \u001B[36mPoolByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    405\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    406\u001B[39m     \u001B[38;5;28mself\u001B[39m.close()\n\u001B[32m--> \u001B[39m\u001B[32m407\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001B[39m, in \u001B[36mPoolByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    401\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> typing.Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m403\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\n\u001B[32m    405\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001B[39m, in \u001B[36mHTTP11ConnectionByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    340\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ShieldCancellation():\n\u001B[32m    341\u001B[39m     \u001B[38;5;28mself\u001B[39m.close()\n\u001B[32m--> \u001B[39m\u001B[32m342\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001B[39m, in \u001B[36mHTTP11ConnectionByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    332\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    333\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[33m\"\u001B[39m\u001B[33mreceive_response_body\u001B[39m\u001B[33m\"\u001B[39m, logger, \u001B[38;5;28mself\u001B[39m._request, kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m334\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connection\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_receive_response_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    335\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    337\u001B[39m     \u001B[38;5;66;03m# If we get an exception while streaming the response,\u001B[39;00m\n\u001B[32m    338\u001B[39m     \u001B[38;5;66;03m# we want to close the response (and possibly the connection)\u001B[39;00m\n\u001B[32m    339\u001B[39m     \u001B[38;5;66;03m# before raising that exception.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001B[39m, in \u001B[36mHTTP11Connection._receive_response_body\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    200\u001B[39m timeout = timeouts.get(\u001B[33m\"\u001B[39m\u001B[33mread\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    202\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m203\u001B[39m     event = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    204\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11.Data):\n\u001B[32m    205\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mbytes\u001B[39m(event.data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001B[39m, in \u001B[36mHTTP11Connection._receive_event\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    214\u001B[39m     event = \u001B[38;5;28mself\u001B[39m._h11_state.next_event()\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11.NEED_DATA:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_network_stream\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    218\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    227\u001B[39m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[32m    228\u001B[39m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[32m    229\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m data == \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI\\LangGraph_DeepSearch\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001B[39m, in \u001B[36mSyncStream.read\u001B[39m\u001B[34m(self, max_bytes, timeout)\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[32m    127\u001B[39m     \u001B[38;5;28mself\u001B[39m._sock.settimeout(timeout)\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T14:18:42.526005300Z",
     "start_time": "2026-02-08T12:24:22.442149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get user input\n",
    "user_input = \"\"\n",
    "\n",
    "# We now update the state as if we are the human_feedback node\n",
    "graph.update_state(thread, {\"human_feedback\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    try:\n",
    "        event[\"messages\"].pretty_print()\n",
    "    except:\n",
    "        pass"
   ],
   "id": "9b8ef37bba59a297",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sub questions are:\n",
      "1. What are the core features and functionalities of LangSmith?\n",
      "2. What are the core features and functionalities of LangGraph?\n",
      "3. How does LangChain differ from LangSmith and LangGraph in terms of features and functionalities?\n",
      "Router decision: search_web\n",
      "Router reasoning: The user is asking for a direct comparison between LangSmith and LangGraph. While sub-questions 1 and 2 cover their individual features, a detailed comparison requires additional information about their specific differences in functionality, use cases, and integration capabilities. Searching the web will provide up-to-date and comprehensive insights to answer this effectively.\n",
      "Relevance check for 'What are the differences and functionalities of La...': True - The search result directly addresses the query by explaining LangSmith's core functionalities as a developer tool for building, debugging, and monitoring LLM applications, providing factual and relevant information.\n",
      "Relevance check for 'Finally figured out the LangChain vs LangGraph vs ...': True - The content directly addresses the comparison between LangChain, LangGraph, and LangSmith, providing specific use cases (basics, complex flows, debugging) that highlight their distinct functionalities and roles.\n",
      "Relevance check for 'LangSmith: The Key to Reliable LLM Applications - ...': True - The search result directly addresses the query by listing core features of LangSmith (tracing/debugging, evaluation framework, LangChain integration, real-time capabilities). It provides specific functional insights relevant to understanding the platform's capabilities.\n",
      "Relevance check for 'LangChain vs LangGraph vs LangSmith vs LangFlow - ...': True - The content directly compares LangChain, LangGraph, and LangSmith by outlining their use cases (prototyping vs workflows vs observability) and provides practical insights into their distinct functionalities, aligning with the query's request for feature/functionality differences.\n",
      "Relevance check for 'CORE Definition & Meaning | Dictionary .com...': False - The search result provides general definitions of the word 'core' and unrelated technical terms, but does not address LangGraph's features, functionalities, or any relevant technical specifications. It lacks direct connection to the query about LangGraph.\n",
      "Relevance check for 'LangSmith docs - Docs by LangChain...': True - The content directly addresses the query by outlining LangSmith's core features (e.g., tracing requests, evaluating outputs, deployment management, framework-agnostic tools) and functionalities (e.g., Studio for no-code prototyping, cloud/self-hosted deployment options). It provides factual, actionable information without promotional bias.\n",
      "For query What are the core features and functionalities of LangSmith?, keeping 3 out of 3 results\n",
      "\n",
      "Relevance check for 'LangChain vs LangGraph vs LangSmith: Complete Comp...': True - The search result directly addresses the query by comparing LangChain, LangGraph, and LangSmith, explaining their distinct roles in building, orchestrating, and monitoring LLM applications. It provides clear functional distinctions and use cases for each tool.\n",
      "For query How does LangChain differ from LangSmith and LangGraph in terms of features and functionalities?, keeping 3 out of 3 results\n",
      "\n",
      "Relevance check for 'CORE definition and meaning | Collins English Dict...': False - The search result provides definitions of the word 'core' in general contexts (e.g., fruit, geology) but does not mention LangGraph or its features/functionality. It lacks direct relevance to the query about LangGraph.\n",
      "Relevance check for 'CORE Definition & Meaning - Merriam-Webster...': False - The search result provides a dictionary definition of the word 'core' and its etymology, which is unrelated to the query about LangGraph's features and functionalities. It contains no information about LangGraph or its technical capabilities.\n",
      "For query What are the core features and functionalities of LangGraph?, keeping 0 out of 3 results\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T14:18:42.528005200Z",
     "start_time": "2026-02-08T12:24:48.533906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state = graph.get_state(thread)\n",
    "print(\"Generated questions:\", state.values.get(\"questions\"))"
   ],
   "id": "29a0c0fe1b08e18f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated questions: ['What are the core features and functionalities of LangSmith?', 'What are the core features and functionalities of LangGraph?', 'How does LangChain differ from LangSmith and LangGraph in terms of features and functionalities?']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T14:18:42.549279700Z",
     "start_time": "2026-02-08T12:24:48.554126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key, value in state.values.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    print(\"------\")"
   ],
   "id": "e5b4736598895437",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages: [AIMessage(content='Breaking down the query into sub-questions:\\n1. What are the core features and functionalities of LangSmith?\\n2. What are the core features and functionalities of LangGraph?', additional_kwargs={}, response_metadata={}, id='7e5be505-a8c7-4ca6-903d-5165724e4add', tool_calls=[], invalid_tool_calls=[]), AIMessage(content='Breaking down the query into sub-questions:\\n1. What are the core features and functionalities of LangSmith?\\n2. What are the core features and functionalities of LangGraph?\\n3. How does LangChain differ from LangSmith and LangGraph in terms of features and functionalities?', additional_kwargs={}, response_metadata={}, id='50e9b376-86f0-4d2c-9d46-d94876c12b07', tool_calls=[], invalid_tool_calls=[]), AIMessage(content='Searched for: **What are the core features and functionalities of LangSmith?** (Found 3 relevant results)', additional_kwargs={}, response_metadata={}, id='defedc4c-854d-4f89-a46c-aed7f77d0dd1', tool_calls=[], invalid_tool_calls=[]), AIMessage(content='Searched for: **What are the core features and functionalities of LangGraph?** (Found 0 relevant results)', additional_kwargs={}, response_metadata={}, id='425dd4c4-89e3-4a03-bae4-1594e4dc31b5', tool_calls=[], invalid_tool_calls=[]), AIMessage(content='Searched for: **How does LangChain differ from LangSmith and LangGraph in terms of features and functionalities?** (Found 3 relevant results)', additional_kwargs={}, response_metadata={}, id='4a3533a7-ce4d-4412-98d5-9704adf50786', tool_calls=[], invalid_tool_calls=[]), AIMessage(content='### Introduction  \\nLangSmith and LangGraph are both tools within the LangChain ecosystem, but they serve distinct purposes. LangSmith focuses on **observability, debugging, and monitoring** of LLM applications, while LangGraph is designed for **orchestrating complex, stateful workflows**. This answer clarifies their differences based on the provided context.\\n\\n---\\n\\n### Detailed Analysis  \\n\\n#### **LangSmith: Observability and Debugging**  \\nLangSmith is a developer tool provided by LangChain, aimed at **building, debugging, and monitoring applications that utilize large language models (LLMs)** [1]. Its core functionalities include:  \\n1. **Tracing and Debugging**: It allows developers to trace requests, evaluate outputs, and debug workflows in real-time [2].  \\n2. **Evaluation Framework**: LangSmith provides tools to test prompts, measure performance, and conduct A/B testing for LLM outputs [2].  \\n3. **Integration with LangChain**: It works seamlessly with LangChains open-source libraries (`langchain` and `langgraph`), enabling developers to prototype locally and deploy to production with integrated monitoring [3].  \\n4. **Observability**: LangSmith combines observability, deployment, and platform setup in one workflow, supporting both managed cloud and self-hosted environments [3].  \\n5. **No-Code Interface**: Its Studio feature allows visual design and deployment of AI agents without writing code, ideal for rapid prototyping [3].  \\n\\nLangSmith is described as the tool for **\"running\"** LLM applications, ensuring reliability and transparency in production [6].  \\n\\n#### **LangGraph: Complex Workflow Orchestration**  \\nLangGraph is designed for **orchestrating complex, stateful workflows** involving multiple agents or steps. Key aspects include:  \\n1. **Stateful Workflows**: It enables the creation of resilient, long-running workflows with multi-agent collaboration, using tools like `StateGraph` and `START/END` nodes [5].  \\n2. **Integration with LangChain**: LangGraph builds on the LangChain ecosystem, leveraging its models, tools, and memory systems to manage complex logic [5].  \\n3. **Use Cases**: It is best suited for **resilient, complex, or multi-agent applications** where linear logic is insufficient [4].  \\n\\nLangGraph is positioned as the tool for **\"building\"** advanced LLM applications, particularly those requiring intricate coordination between components [6].  \\n\\n#### **Key Differences**  \\n| Feature                | **LangSmith**                          | **LangGraph**                          |  \\n|------------------------|----------------------------------------|----------------------------------------|  \\n| **Primary Purpose**    | Observability, debugging, and monitoring [2] | Orchestrating complex workflows [5]   |  \\n| **Workflow Complexity**| Linear or simple logic [4]             | Stateful, multi-agent, or long-running [5] |  \\n| **Integration**        | Works with LangChain and LangGraph [3] | Builds on LangChains ecosystem [5]   |  \\n| **Use Case**           | Production monitoring and optimization [6] | Complex agent collaboration [6]       |  \\n\\n---\\n\\n### References  \\n[1] LangSmith: The Key to Reliable LLM Applications - Nitor Infotech, https://www.nitorinfotech.com/blog/langsmith-the-key-to-reliable-llm-applications/  \\n[2] What are the differences and functionalities of LangSmith ... - Hashnode, https://saimaharana.hashnode.dev/what-are-the-differences-and-functionalities-of-langsmith-langserve-templates-langchain-langchain-community-and-langchain-core  \\n[3] LangSmith docs - Docs by LangChain, https://docs.langchain.com/langsmith/home  \\n[4] Finally figured out the LangChain vs LangGraph vs LangSmith ... - Reddit, https://www.reddit.com/r/Rag/comments/1mxs81z/finally_figured_out_the_langchain_vs_langgraph_vs/  \\n[5] LangChain vs LangGraph vs LangSmith vs LangFlow - DataCamp, https://www.datacamp.com/tutorial/langchain-vs-langgraph-vs-langsmith-vs-langflow  \\n[6] LangChain vs LangGraph vs LangSmith: Complete Comparison ... - LangCopilot, https://langcopilot.com/posts/2025-09-24-langchain-vs-langgraph-vs-langsmith-which', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2026-02-08T12:24:48.5096579Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7853091400, 'load_duration': 51572700, 'prompt_eval_count': 2824, 'prompt_eval_duration': 228788000, 'eval_count': 1408, 'eval_duration': 7324789000, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'}, id='lc_run--019c3d36-15d0-7ab0-b2b2-b46944fce263-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 2824, 'output_tokens': 1408, 'total_tokens': 4232})]\n",
      "------\n",
      "query: What's the difference between LangSmith and LangGraph?\n",
      "------\n",
      "questions: ['What are the core features and functionalities of LangSmith?', 'What are the core features and functionalities of LangGraph?', 'How does LangChain differ from LangSmith and LangGraph in terms of features and functionalities?']\n",
      "------\n",
      "break_questions_iterations_count: 2\n",
      "------\n",
      "human_feedback: \n",
      "------\n",
      "search_results: [{'question': 'What are the core features and functionalities of LangSmith?', 'results': [{'title': 'What are the differences and functionalities of LangSmith ...', 'url': 'https://saimaharana.hashnode.dev/what-are-the-differences-and-functionalities-of-langsmith-langserve-templates-langchain-langchain-community-and-langchain-core', 'content': 'Functionality: LangSmith is a developer tool provided by LangChain aimed at building, debugging, and monitoring applications that utilize LLMs'}, {'title': 'LangSmith: The Key to Reliable LLM Applications - Nitor Infotech', 'url': 'https://www.nitorinfotech.com/blog/langsmith-the-key-to-reliable-llm-applications/', 'content': 'What Are the Key Features of LangSmith?  1. Tracing and Debugging  2. Evaluation Framework  3. Integration with LangChain  4. Real-Time'}, {'title': 'LangSmith docs - Docs by LangChain', 'url': 'https://docs.langchain.com/langsmith/home', 'content': '* Create an account and API key. # LangSmith docs. **LangSmith provides tools for developing, debugging, and deploying LLM applications.** It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place. LangSmith is framework agnostic, so you can use it with or without LangChains open-source libraries `langchain` and `langgraph`. Prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems. LangGraph Platform is now LangSmith Deployment. Go to your Settings page  **API Keys**  **Create API Key**. Once your account and API key are ready, choose a quickstart to begin building with LangSmith:. Use LangSmith in managed cloud, in a self-hosted environment, or hybrid to match your infrastructure and compliance needs.## Studio. Design and deploy AI agents visually with a no-code interfaceperfect for rapid prototyping and getting started without writing code. LangSmith combines observability, evaluation, deployment, and platform setup in one integrated workflowfrom local development to production.'}]}, {'question': 'What are the core features and functionalities of LangGraph?', 'results': []}, {'question': 'How does LangChain differ from LangSmith and LangGraph in terms of features and functionalities?', 'results': [{'title': 'Finally figured out the LangChain vs LangGraph vs LangSmith ...', 'url': 'https://www.reddit.com/r/Rag/comments/1mxs81z/finally_figured_out_the_langchain_vs_langgraph_vs/', 'content': \"LangChain for the basics, LangGraph for complex flows, LangSmith to see what's actually happening under the hood. Anyone else been through this\"}, {'title': 'LangChain vs LangGraph vs LangSmith vs LangFlow - DataCamp', 'url': 'https://www.datacamp.com/tutorial/langchain-vs-langgraph-vs-langsmith-vs-langflow', 'content': 'Quick heuristic: Start with LangChain, move to LangGraph as workflows grow, add LangSmith for observability, use LangFlow when you need fast iteration or collaboration. I believe it makes sense to start with a bit of history around the LangChain ecosystem; its become the go-to framework for agentic AI, and knowing how it got here will make it easier to see why LangGraph, LangSmith, and LangFlow matter. from typing import TypedDict, Annotated, List from langgraph.graph import StateGraph, START, END from langgraph.graph.message import add_messages from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage, AIMessage # Defining the state class State(TypedDict): messages: Annotated[List, add_messages] llm = ChatOpenAI(model=\"gpt-4o-mini\") def answer_node(state: State): # Normal answer using the whole chat history. | **Best for** | Prototyping, linear logic, quick apps | Resilient, complex, long-running or multi-agent apps | Observability, debugging, regression tests, A/B evaluations | Visual prototyping, stakeholder reviews, and exporting to LangChain code |. **LangGraph builds on the LangChain ecosystem (models, tools, memory).'}, {'title': 'LangChain vs LangGraph vs LangSmith: Complete Comparison ...', 'url': 'https://langcopilot.com/posts/2025-09-24-langchain-vs-langgraph-vs-langsmith-which', 'content': \"Complete LangChain ecosystem comparison: LangChain for building chains, LangGraph for complex agents, LangSmith for monitoring. #LangChain vs LangGraph#LangChain#LangGraph#LangSmith#AI Agent#Agent Development#LLM Development. In short, **LangChain provides the core components for LLM apps, LangGraph orchestrates complex, stateful agent workflows, and LangSmith offers the essential observability to debug, monitor, and optimize them in production.** Understanding their distinct roles is crucial for building a modern LLM stack. ## LangGraph: Orchestrating Complex LLM Agent Workflows. ## LangSmith: LLM Observability and Ops. If LangChain and LangGraph are for *building* your app, LangSmith is for *running* it. A common and powerful pattern emerges: **use LangChain to build the components, LangGraph to orchestrate the workflow, and LangSmith to monitor the entire system.**. You'd use LangChain to construct the core capabilities of each individual agent, LangGraph to manage the complex collaboration between them, and LangSmith to keep the entire LLM stack running smoothly, efficiently, and transparently. When building production applications with LangChain, LangGraph, or LangSmith, managing API costs is crucial.\"}]}]\n",
      "------\n",
      "sources: [{'question': 'What are the core features and functionalities of LangSmith?', 'results': [{'title': 'What are the differences and functionalities of LangSmith ...', 'url': 'https://saimaharana.hashnode.dev/what-are-the-differences-and-functionalities-of-langsmith-langserve-templates-langchain-langchain-community-and-langchain-core', 'content': 'Functionality: LangSmith is a developer tool provided by LangChain aimed at building, debugging, and monitoring applications that utilize LLMs'}, {'title': 'LangSmith: The Key to Reliable LLM Applications - Nitor Infotech', 'url': 'https://www.nitorinfotech.com/blog/langsmith-the-key-to-reliable-llm-applications/', 'content': 'What Are the Key Features of LangSmith?  1. Tracing and Debugging  2. Evaluation Framework  3. Integration with LangChain  4. Real-Time'}, {'title': 'LangSmith docs - Docs by LangChain', 'url': 'https://docs.langchain.com/langsmith/home', 'content': '* Create an account and API key. # LangSmith docs. **LangSmith provides tools for developing, debugging, and deploying LLM applications.** It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place. LangSmith is framework agnostic, so you can use it with or without LangChains open-source libraries `langchain` and `langgraph`. Prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems. LangGraph Platform is now LangSmith Deployment. Go to your Settings page  **API Keys**  **Create API Key**. Once your account and API key are ready, choose a quickstart to begin building with LangSmith:. Use LangSmith in managed cloud, in a self-hosted environment, or hybrid to match your infrastructure and compliance needs.## Studio. Design and deploy AI agents visually with a no-code interfaceperfect for rapid prototyping and getting started without writing code. LangSmith combines observability, evaluation, deployment, and platform setup in one integrated workflowfrom local development to production.'}]}, {'question': 'What are the core features and functionalities of LangGraph?', 'results': []}, {'question': 'How does LangChain differ from LangSmith and LangGraph in terms of features and functionalities?', 'results': [{'title': 'Finally figured out the LangChain vs LangGraph vs LangSmith ...', 'url': 'https://www.reddit.com/r/Rag/comments/1mxs81z/finally_figured_out_the_langchain_vs_langgraph_vs/', 'content': \"LangChain for the basics, LangGraph for complex flows, LangSmith to see what's actually happening under the hood. Anyone else been through this\"}, {'title': 'LangChain vs LangGraph vs LangSmith vs LangFlow - DataCamp', 'url': 'https://www.datacamp.com/tutorial/langchain-vs-langgraph-vs-langsmith-vs-langflow', 'content': 'Quick heuristic: Start with LangChain, move to LangGraph as workflows grow, add LangSmith for observability, use LangFlow when you need fast iteration or collaboration. I believe it makes sense to start with a bit of history around the LangChain ecosystem; its become the go-to framework for agentic AI, and knowing how it got here will make it easier to see why LangGraph, LangSmith, and LangFlow matter. from typing import TypedDict, Annotated, List from langgraph.graph import StateGraph, START, END from langgraph.graph.message import add_messages from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage, AIMessage # Defining the state class State(TypedDict): messages: Annotated[List, add_messages] llm = ChatOpenAI(model=\"gpt-4o-mini\") def answer_node(state: State): # Normal answer using the whole chat history. | **Best for** | Prototyping, linear logic, quick apps | Resilient, complex, long-running or multi-agent apps | Observability, debugging, regression tests, A/B evaluations | Visual prototyping, stakeholder reviews, and exporting to LangChain code |. **LangGraph builds on the LangChain ecosystem (models, tools, memory).'}, {'title': 'LangChain vs LangGraph vs LangSmith: Complete Comparison ...', 'url': 'https://langcopilot.com/posts/2025-09-24-langchain-vs-langgraph-vs-langsmith-which', 'content': \"Complete LangChain ecosystem comparison: LangChain for building chains, LangGraph for complex agents, LangSmith for monitoring. #LangChain vs LangGraph#LangChain#LangGraph#LangSmith#AI Agent#Agent Development#LLM Development. In short, **LangChain provides the core components for LLM apps, LangGraph orchestrates complex, stateful agent workflows, and LangSmith offers the essential observability to debug, monitor, and optimize them in production.** Understanding their distinct roles is crucial for building a modern LLM stack. ## LangGraph: Orchestrating Complex LLM Agent Workflows. ## LangSmith: LLM Observability and Ops. If LangChain and LangGraph are for *building* your app, LangSmith is for *running* it. A common and powerful pattern emerges: **use LangChain to build the components, LangGraph to orchestrate the workflow, and LangSmith to monitor the entire system.**. You'd use LangChain to construct the core capabilities of each individual agent, LangGraph to manage the complex collaboration between them, and LangSmith to keep the entire LLM stack running smoothly, efficiently, and transparently. When building production applications with LangChain, LangGraph, or LangSmith, managing API costs is crucial.\"}]}]\n",
      "------\n",
      "summary: content='### Introduction  \\nLangSmith and LangGraph are both tools within the LangChain ecosystem, but they serve distinct purposes. LangSmith focuses on **observability, debugging, and monitoring** of LLM applications, while LangGraph is designed for **orchestrating complex, stateful workflows**. This answer clarifies their differences based on the provided context.\\n\\n---\\n\\n### Detailed Analysis  \\n\\n#### **LangSmith: Observability and Debugging**  \\nLangSmith is a developer tool provided by LangChain, aimed at **building, debugging, and monitoring applications that utilize large language models (LLMs)** [1]. Its core functionalities include:  \\n1. **Tracing and Debugging**: It allows developers to trace requests, evaluate outputs, and debug workflows in real-time [2].  \\n2. **Evaluation Framework**: LangSmith provides tools to test prompts, measure performance, and conduct A/B testing for LLM outputs [2].  \\n3. **Integration with LangChain**: It works seamlessly with LangChains open-source libraries (`langchain` and `langgraph`), enabling developers to prototype locally and deploy to production with integrated monitoring [3].  \\n4. **Observability**: LangSmith combines observability, deployment, and platform setup in one workflow, supporting both managed cloud and self-hosted environments [3].  \\n5. **No-Code Interface**: Its Studio feature allows visual design and deployment of AI agents without writing code, ideal for rapid prototyping [3].  \\n\\nLangSmith is described as the tool for **\"running\"** LLM applications, ensuring reliability and transparency in production [6].  \\n\\n#### **LangGraph: Complex Workflow Orchestration**  \\nLangGraph is designed for **orchestrating complex, stateful workflows** involving multiple agents or steps. Key aspects include:  \\n1. **Stateful Workflows**: It enables the creation of resilient, long-running workflows with multi-agent collaboration, using tools like `StateGraph` and `START/END` nodes [5].  \\n2. **Integration with LangChain**: LangGraph builds on the LangChain ecosystem, leveraging its models, tools, and memory systems to manage complex logic [5].  \\n3. **Use Cases**: It is best suited for **resilient, complex, or multi-agent applications** where linear logic is insufficient [4].  \\n\\nLangGraph is positioned as the tool for **\"building\"** advanced LLM applications, particularly those requiring intricate coordination between components [6].  \\n\\n#### **Key Differences**  \\n| Feature                | **LangSmith**                          | **LangGraph**                          |  \\n|------------------------|----------------------------------------|----------------------------------------|  \\n| **Primary Purpose**    | Observability, debugging, and monitoring [2] | Orchestrating complex workflows [5]   |  \\n| **Workflow Complexity**| Linear or simple logic [4]             | Stateful, multi-agent, or long-running [5] |  \\n| **Integration**        | Works with LangChain and LangGraph [3] | Builds on LangChains ecosystem [5]   |  \\n| **Use Case**           | Production monitoring and optimization [6] | Complex agent collaboration [6]       |  \\n\\n---\\n\\n### References  \\n[1] LangSmith: The Key to Reliable LLM Applications - Nitor Infotech, https://www.nitorinfotech.com/blog/langsmith-the-key-to-reliable-llm-applications/  \\n[2] What are the differences and functionalities of LangSmith ... - Hashnode, https://saimaharana.hashnode.dev/what-are-the-differences-and-functionalities-of-langsmith-langserve-templates-langchain-langchain-community-and-langchain-core  \\n[3] LangSmith docs - Docs by LangChain, https://docs.langchain.com/langsmith/home  \\n[4] Finally figured out the LangChain vs LangGraph vs LangSmith ... - Reddit, https://www.reddit.com/r/Rag/comments/1mxs81z/finally_figured_out_the_langchain_vs_langgraph_vs/  \\n[5] LangChain vs LangGraph vs LangSmith vs LangFlow - DataCamp, https://www.datacamp.com/tutorial/langchain-vs-langgraph-vs-langsmith-vs-langflow  \\n[6] LangChain vs LangGraph vs LangSmith: Complete Comparison ... - LangCopilot, https://langcopilot.com/posts/2025-09-24-langchain-vs-langgraph-vs-langsmith-which' additional_kwargs={} response_metadata={'model': 'qwen3:8b', 'created_at': '2026-02-08T12:24:48.5096579Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7853091400, 'load_duration': 51572700, 'prompt_eval_count': 2824, 'prompt_eval_duration': 228788000, 'eval_count': 1408, 'eval_duration': 7324789000, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'} id='lc_run--019c3d36-15d0-7ab0-b2b2-b46944fce263-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 2824, 'output_tokens': 1408, 'total_tokens': 4232}\n",
      "------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T14:18:42.549279700Z",
     "start_time": "2026-02-08T12:24:48.573412Z"
    }
   },
   "cell_type": "code",
   "source": "state.values.get(\"summary\").pretty_print()",
   "id": "d6ca12969a2857d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "### Introduction  \n",
      "LangSmith and LangGraph are both tools within the LangChain ecosystem, but they serve distinct purposes. LangSmith focuses on **observability, debugging, and monitoring** of LLM applications, while LangGraph is designed for **orchestrating complex, stateful workflows**. This answer clarifies their differences based on the provided context.\n",
      "\n",
      "---\n",
      "\n",
      "### Detailed Analysis  \n",
      "\n",
      "#### **LangSmith: Observability and Debugging**  \n",
      "LangSmith is a developer tool provided by LangChain, aimed at **building, debugging, and monitoring applications that utilize large language models (LLMs)** [1]. Its core functionalities include:  \n",
      "1. **Tracing and Debugging**: It allows developers to trace requests, evaluate outputs, and debug workflows in real-time [2].  \n",
      "2. **Evaluation Framework**: LangSmith provides tools to test prompts, measure performance, and conduct A/B testing for LLM outputs [2].  \n",
      "3. **Integration with LangChain**: It works seamlessly with LangChains open-source libraries (`langchain` and `langgraph`), enabling developers to prototype locally and deploy to production with integrated monitoring [3].  \n",
      "4. **Observability**: LangSmith combines observability, deployment, and platform setup in one workflow, supporting both managed cloud and self-hosted environments [3].  \n",
      "5. **No-Code Interface**: Its Studio feature allows visual design and deployment of AI agents without writing code, ideal for rapid prototyping [3].  \n",
      "\n",
      "LangSmith is described as the tool for **\"running\"** LLM applications, ensuring reliability and transparency in production [6].  \n",
      "\n",
      "#### **LangGraph: Complex Workflow Orchestration**  \n",
      "LangGraph is designed for **orchestrating complex, stateful workflows** involving multiple agents or steps. Key aspects include:  \n",
      "1. **Stateful Workflows**: It enables the creation of resilient, long-running workflows with multi-agent collaboration, using tools like `StateGraph` and `START/END` nodes [5].  \n",
      "2. **Integration with LangChain**: LangGraph builds on the LangChain ecosystem, leveraging its models, tools, and memory systems to manage complex logic [5].  \n",
      "3. **Use Cases**: It is best suited for **resilient, complex, or multi-agent applications** where linear logic is insufficient [4].  \n",
      "\n",
      "LangGraph is positioned as the tool for **\"building\"** advanced LLM applications, particularly those requiring intricate coordination between components [6].  \n",
      "\n",
      "#### **Key Differences**  \n",
      "| Feature                | **LangSmith**                          | **LangGraph**                          |  \n",
      "|------------------------|----------------------------------------|----------------------------------------|  \n",
      "| **Primary Purpose**    | Observability, debugging, and monitoring [2] | Orchestrating complex workflows [5]   |  \n",
      "| **Workflow Complexity**| Linear or simple logic [4]             | Stateful, multi-agent, or long-running [5] |  \n",
      "| **Integration**        | Works with LangChain and LangGraph [3] | Builds on LangChains ecosystem [5]   |  \n",
      "| **Use Case**           | Production monitoring and optimization [6] | Complex agent collaboration [6]       |  \n",
      "\n",
      "---\n",
      "\n",
      "### References  \n",
      "[1] LangSmith: The Key to Reliable LLM Applications - Nitor Infotech, https://www.nitorinfotech.com/blog/langsmith-the-key-to-reliable-llm-applications/  \n",
      "[2] What are the differences and functionalities of LangSmith ... - Hashnode, https://saimaharana.hashnode.dev/what-are-the-differences-and-functionalities-of-langsmith-langserve-templates-langchain-langchain-community-and-langchain-core  \n",
      "[3] LangSmith docs - Docs by LangChain, https://docs.langchain.com/langsmith/home  \n",
      "[4] Finally figured out the LangChain vs LangGraph vs LangSmith ... - Reddit, https://www.reddit.com/r/Rag/comments/1mxs81z/finally_figured_out_the_langchain_vs_langgraph_vs/  \n",
      "[5] LangChain vs LangGraph vs LangSmith vs LangFlow - DataCamp, https://www.datacamp.com/tutorial/langchain-vs-langgraph-vs-langsmith-vs-langflow  \n",
      "[6] LangChain vs LangGraph vs LangSmith: Complete Comparison ... - LangCopilot, https://langcopilot.com/posts/2025-09-24-langchain-vs-langgraph-vs-langsmith-which\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
